==========check_data_files is running ====================
==========check_data_files is done ====================

==========process_data is running ====================
Start with feature engineering.
Start creating sequences.

Data preprocessing completed:
Training set shape: (153291, 1440, 19)
Test set shape: (38323, 1440, 19)
Number of features: 19

Feature list:
1. hour_sin
2. hour_cos
3. minute_sin
4. minute_cos
5. day_of_week_sin
6. day_of_week_cos
7. month_sin
8. month_cos
9. is_weekend
10. is_holiday
11. temperature
12. temp_rolling_mean_24h
13. temp_diff
14. temp_rolling_std_24h
15. load
16. load_rolling_mean_24h
17. load_rolling_std_24h
18. load_rolling_mean_7d
19. temp_load_interaction
==========process_data is done ====================

==========create_visualizations is running ====================
Starting data visualization...
Plot saved: daily_pattern.png
Plot saved: temp_load_relationship.png
Data visualization completed successfully
==========create_visualizations is done ====================

==========compare_models is running ====================
Starting model comparison...
Starting model comparison...
================================================================================
================================================================================

Evaluating Time Series model...

======================================== Time Series Model ========================================
Starting data preprocessing...
Preparing final prediction...
Prediction plot saved in model_comparison\model-time_series dir

Prediction Summary:
Mean Load: 7759.02 MW
Standard Deviation: 811.98 MW
Maximum Load: 8765.72 MW
Minimum Load: 6022.73 MW

Time Series Evaluation Results:
------------------------------------------------------------
Status: Successfully completed
Execution time: 1.31 seconds

Metrics:
----------------------------------------
MSE             : 228035.7373
RMSE            : 477.5309
MAE             : 378.5029
R2              : 0.5443
MAPE            : 5.0857
execution_time  : 1.3094

================================================================================
================================================================================

Evaluating Prophet model...

======================================== Prophet Model ========================================
Starting data preprocessing for Prophet...
Evaluating 1 parameter combinations

Trying parameters: {'changepoint_prior_scale': 0.01, 'seasonality_prior_scale': 0.1, 'seasonality_mode': 'multiplicative', 'changepoint_range': 0.9, 'holidays_prior_scale': 0.1}
New best parameters found: MSE=714046.00, MAE=627.11

Training final model with best parameters...
Generating predictions...
Prophet prediction plot saved in model_comparison\model-prophet

Prophet Prediction Summary:
Mean Load: 7376.20 MW
Standard Deviation: 737.93 MW
Maximum Load: 8487.17 MW
Minimum Load: 5812.36 MW

Prophet Evaluation Results:
------------------------------------------------------------
Status: Successfully completed
Execution time: 129.34 seconds

Metrics:
----------------------------------------
MSE             : 93393.4491
RMSE            : 305.6034
MAE             : 232.7323
R2              : 0.8134
MAPE            : 3.1800
execution_time  : 129.3388

================================================================================
================================================================================

Evaluating MLP model...

======================================== MLP Model ========================================
Starting data preprocessing...
Training MLP with input shape: (196321, 384), output shape: (196321, 96)
Training MLP model...
Iteration 1, loss = 0.00920350
Validation score: 0.481993
Iteration 2, loss = 0.00412950
Validation score: 0.618449
Iteration 3, loss = 0.00339593
Validation score: 0.648816
Iteration 4, loss = 0.00329091
Validation score: 0.652145
Iteration 5, loss = 0.00327207
Validation score: 0.654476
Iteration 6, loss = 0.00326314
Validation score: 0.645126
Iteration 7, loss = 0.00326057
Validation score: 0.655551
Iteration 8, loss = 0.00325184
Validation score: 0.651492
Iteration 9, loss = 0.00325084
Validation score: 0.654697
Iteration 10, loss = 0.00324281
Validation score: 0.655979
Iteration 11, loss = 0.00324129
Validation score: 0.654256
Iteration 12, loss = 0.00324187
Validation score: 0.655269
Iteration 13, loss = 0.00323397
Validation score: 0.653328
Iteration 14, loss = 0.00323641
Validation score: 0.656570
Iteration 15, loss = 0.00323215
Validation score: 0.644460
Iteration 16, loss = 0.00323102
Validation score: 0.657357
Iteration 17, loss = 0.00316942
Validation score: 0.689658
Iteration 18, loss = 0.00286501
Validation score: 0.693026
Iteration 19, loss = 0.00282105
Validation score: 0.700872
Iteration 20, loss = 0.00277451
Validation score: 0.704992
Iteration 21, loss = 0.00273984
Validation score: 0.706571
Iteration 22, loss = 0.00270316
Validation score: 0.715044
Iteration 23, loss = 0.00265040
Validation score: 0.719574
Iteration 24, loss = 0.00264572
Validation score: 0.701690
Iteration 25, loss = 0.00264240
Validation score: 0.717739
Iteration 26, loss = 0.00264460
Validation score: 0.719615
Iteration 27, loss = 0.00263677
Validation score: 0.719306
Iteration 28, loss = 0.00263830
Validation score: 0.715078
Iteration 29, loss = 0.00263662
Validation score: 0.718256
Iteration 30, loss = 0.00263325
Validation score: 0.712170
Iteration 31, loss = 0.00263457
Validation score: 0.720390
Iteration 32, loss = 0.00263868
Validation score: 0.719452
Iteration 33, loss = 0.00263170
Validation score: 0.719926
Iteration 34, loss = 0.00263131
Validation score: 0.711501
Iteration 35, loss = 0.00263418
Validation score: 0.720609
Iteration 36, loss = 0.00263214
Validation score: 0.717648
Iteration 37, loss = 0.00262802
Validation score: 0.718670
Iteration 38, loss = 0.00262666
Validation score: 0.721282
Iteration 39, loss = 0.00263357
Validation score: 0.720730
Iteration 40, loss = 0.00262629
Validation score: 0.717898
Iteration 41, loss = 0.00263230
Validation score: 0.718397
Iteration 42, loss = 0.00262452
Validation score: 0.720468
Iteration 43, loss = 0.00263103
Validation score: 0.721004
Iteration 44, loss = 0.00262877
Validation score: 0.720748
Iteration 45, loss = 0.00263220
Validation score: 0.720830
Iteration 46, loss = 0.00262512
Validation score: 0.718996
Iteration 47, loss = 0.00262939
Validation score: 0.720696
Iteration 48, loss = 0.00263310
Validation score: 0.716757
Iteration 49, loss = 0.00262653
Validation score: 0.721724
Iteration 50, loss = 0.00263181
Validation score: 0.720864
Iteration 51, loss = 0.00262494
Validation score: 0.721349
Iteration 52, loss = 0.00262373
Validation score: 0.719162
Iteration 53, loss = 0.00262850
Validation score: 0.720724
Iteration 54, loss = 0.00262581
Validation score: 0.722057
Iteration 55, loss = 0.00262647
Validation score: 0.718365
Iteration 56, loss = 0.00262661
Validation score: 0.720743
Iteration 57, loss = 0.00262608
Validation score: 0.720318
Iteration 58, loss = 0.00262488
Validation score: 0.721060
Iteration 59, loss = 0.00262917
Validation score: 0.719473
Iteration 60, loss = 0.00262659
Validation score: 0.720705
Iteration 61, loss = 0.00262206
Validation score: 0.721932
Iteration 62, loss = 0.00262243
Validation score: 0.721256
Iteration 63, loss = 0.00262461
Validation score: 0.721521
Iteration 64, loss = 0.00262406
Validation score: 0.716821
Iteration 65, loss = 0.00262187
Validation score: 0.716992
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model training completed
Generating predictions...
MLP prediction plot saved in model_comparison\model-mlp

MLP Prediction Summary:
Mean Load: 7665.38 MW
Standard Deviation: 683.52 MW
Maximum Load: 8767.79 MW
Minimum Load: 6273.44 MW

MLP Evaluation Results:
------------------------------------------------------------
Status: Successfully completed
Execution time: 111.30 seconds

Metrics:
----------------------------------------
MSE             : 153731.7066
RMSE            : 392.0864
MAE             : 331.0450
R2              : 0.6928
MAPE            : 4.6261
execution_time  : 111.3041

================================================================================
================================================================================

Evaluating BNN model...

======================================== BNN Model ========================================
Starting data preprocessing for BNN...
Training MC Dropout Network with input shape: (196321, 384), output shape: (196321, 96)
Training MC Dropout model...
Training completed - Final loss: 0.0063, Validation loss: 0.0070
Generating predictions with MC Dropout sampling...
BNN prediction plot saved in model_comparison\model-bnn

BNN Prediction Summary:
Mean Load: 7472.28 MW
Standard Deviation: 607.79 MW
Maximum Load: 8224.55 MW
Minimum Load: 6208.95 MW
Average Uncertainty: Â±529.26 MW

BNN Evaluation Results:
------------------------------------------------------------
Status: Successfully completed
Execution time: 213.61 seconds

Metrics:
----------------------------------------
MSE             : 123036.7962
RMSE            : 350.7660
MAE             : 296.6365
R2              : 0.7542
MAPE            : 4.0508
execution_time  : 213.6127

================================================================================
================================================================================

Evaluating CNN model...

======================================== CNN Model ========================================
Starting data preprocessing...
Training CNN with input shape: (196321, 96, 4), output shape: (196321, 96)
Training CNN model...
Model training completed
Generating predictions...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 64ms/step
CNN prediction plot saved in model_comparison\model-cnn

CNN Prediction Summary:
Mean Load: 7493.13 MW
Standard Deviation: 677.13 MW
Maximum Load: 8695.31 MW
Minimum Load: 5932.81 MW
Minimum Load: 5932.81 MW

CNN Evaluation Results:
------------------------------------------------------------
Status: Successfully completed
Execution time: 432.57 seconds

Metrics:
----------------------------------------
MSE             : 55068.2095
RMSE            : 234.6662
MAE             : 184.2542
R2              : 0.8900
MAPE            : 2.5419
execution_time  : 432.5734

================================================================================
================================================================================

Evaluating LSTM model...

======================================== LSTM Model ========================================
Starting data preprocessing...
Training LSTM with input shape: (196321, 96, 4), output shape: (196321, 96)
LSTM model structure:
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 96, 64)            17664     
                                                                 
 dropout_4 (Dropout)         (None, 96, 64)            0         
                                                                 
 lstm_1 (LSTM)               (None, 32)                12416     
                                                                 
 dropout_5 (Dropout)         (None, 32)                0         
                                                                 
 dense_7 (Dense)             (None, 96)                3168      
                                                                 
=================================================================
Total params: 33248 (129.88 KB)
Trainable params: 33248 (129.88 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Training LSTM model...
Generating predictions...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 123ms/step
LSTM prediction plot saved in model_comparison\model-lstm

LSTM Prediction Summary:
Mean Load: 7427.50 MW
Standard Deviation: 574.14 MW
Maximum Load: 8364.31 MW
Minimum Load: 6195.26 MW

LSTM Evaluation Results:
------------------------------------------------------------
Status: Successfully completed
Execution time: 1725.79 seconds

Metrics:
----------------------------------------
MSE             : 48430.4226
RMSE            : 220.0691
MAE             : 164.2289
R2              : 0.9032
MAPE            : 2.3129
execution_time  : 1725.7917

================================================================================
================================================================================

Evaluating XGBoost model...

======================================== XGBoost Model ========================================
Starting data preprocessing...
Created sequences with shape: X=(196321, 96, 11), y=(196321, 96)
Training XGBoost ensemble models...
Model 1 training completed
Model 2 training completed
Model 3 training completed
Generating predictions...
XGBoost prediction plot saved in model_comparison\model-xgboost

XGBoost Ensemble Prediction Summary:
Mean Load: 425.44 MW
Standard Deviation: 188.70 MW
Maximum Load: 869.54 MW
Minimum Load: 119.85 MW

XGBoost Evaluation Results:
------------------------------------------------------------
Status: Successfully completed
Execution time: 5117.24 seconds

Metrics:
----------------------------------------
MSE             : 48953281.5478
RMSE            : 6996.6622
MAE             : 6955.7791
R2              : -96.8176
MAPE            : 94.1405
execution_time  : 5117.2388

================================================================================
================================================================================

Evaluating Random Forest model...

======================================== Random Forest Model ========================================
Starting data preprocessing...
Training Random Forest with input shape: (196321, 1056), output shape: (196321, 96)
Training Random Forest model...
Model training completed
Generating predictions...
Random Forest prediction plot saved in model_comparison\model-random_forest

Random Forest Prediction Summary:
Mean Load: 7409.80 MW
Standard Deviation: 5.45 MW
Maximum Load: 7418.95 MW
Minimum Load: 7396.64 MW

Feature Importance:
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0005
Feature importance: 0.0020
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0005
Feature importance: 0.0025
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0007
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0009
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0005
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0006
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0006
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0005
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0005
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0005
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0005
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0022
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0024
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0013
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0018
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0047
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0093
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0032
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0032
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0029
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0020
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0013
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0007
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0008
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0010
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0029
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0033
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0067
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0052
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0031
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0012
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0007
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0006
Feature importance: 0.0017
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0006
Feature importance: 0.0040
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0059
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0097
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0070
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0185
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0004
Feature importance: 0.0108
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0012
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0004
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0005
Feature importance: 0.0003
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0006
Feature importance: 0.0002
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0004
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0004
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0003
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0004
Feature importance: 0.0003
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0009
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0011
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0013
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0014
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0016
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0018
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0016
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0013
Feature importance: 0.0001
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0011
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0005
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0010
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0005
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0001
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0009
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0007
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0002
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0007
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0002
Feature importance: 0.0000
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0003
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0004
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0003
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0001
Feature importance: 0.0006
Feature importance: 0.0005
Feature importance: 0.0001
Feature importance: 0.0002
Feature importance: 0.0005
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0007
Feature importance: 0.0001
Feature importance: 0.0009
Feature importance: 0.0001
Feature importance: 0.0008
Feature importance: 0.0008
Feature importance: 0.0001
Feature importance: 0.0003
Feature importance: 0.0010
Feature importance: 0.0000
Feature importance: 0.0000
Feature importance: 0.0012
Feature importance: 0.0001
Feature importance: 0.0028
Feature importance: 0.0001
Feature importance: 0.0020
Feature importance: 0.0036
Feature importance: 0.0002
Feature importance: 0.0004
Feature importance: 0.6806

Random Forest Evaluation Results:
------------------------------------------------------------
Status: Successfully completed
Execution time: 6698.86 seconds

Metrics:
----------------------------------------
MSE             : 501296.0283
RMSE            : 708.0226
MAE             : 542.5661
R2              : -0.0017
MAPE            : 7.7113
execution_time  : 6698.8553

================================================================================

Model Comparison Summary:
                Time Series     Prophet  ...       XGBoost  Random Forest
MSE             228035.7373  93393.4491  ...  4.895328e+07    501296.0283
RMSE               477.5309    305.6034  ...  6.996662e+03       708.0226
MAE                378.5029    232.7323  ...  6.955779e+03       542.5661
R2                   0.5443      0.8134  ... -9.681760e+01        -0.0017
MAPE                 5.0857      3.1800  ...  9.414050e+01         7.7113
execution_time       1.3094    129.3388  ...  5.117239e+03      6698.8553

[6 rows x 8 columns]
Model comparison completed
==========compare_models is done ====================

